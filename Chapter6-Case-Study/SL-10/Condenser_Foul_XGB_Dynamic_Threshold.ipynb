{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "from sklearn.metrics import precision_score, mean_squared_error, r2_score, make_scorer, adjusted_rand_score, \\\n",
    "                    accuracy_score, f1_score, confusion_matrix, classification_report, roc_auc_score, recall_score\n",
    "from time import time\n",
    "import scipy.stats as st\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pprint as pp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Chiller_Data = pd.read_excel('Condenser_Fouling_Fault_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Chiller_Data = Chiller_Data.loc[Chiller_Data['kW'] != 1.682000e-45]\n",
    "Chiller_Data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Chiller_Data['Target'] = (Chiller_Data['TRC_sub'])/(Chiller_Data['TRC']-Chiller_Data['TCI'])\n",
    "Chiller_Data['Lag1'] = (Chiller_Data['Target'].shift(1))\n",
    "Chiller_Data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = Chiller_Data['Target'].as_matrix()\n",
    "True_Labels = Chiller_Data['Label'].as_matrix()\n",
    "Chiller_Data.drop(['Target','Label','Time (minutes)'], axis=1, inplace=True)\n",
    "#Feature_Names = ['Lag1','TEI','TEO','TCI','TCO','kW','FWC','FWE','TEA','TCA','TRE','PRE','TRC','PRC','TRC_sub','T_suc',\n",
    "#                'Tsh_suc','TR_dis','Tsh_dis','P_lift','TO_sump','TO_feed','PO_feed','TWCD','TWED']\n",
    "Feature_Names = list(Chiller_Data)\n",
    "X = Chiller_Data[Feature_Names].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.55, shuffle=False)\n",
    "TL_train, TL_Test = train_test_split(True_Labels, test_size=0.55, shuffle=False)\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_dyn_threshold(A, P, I, N):\n",
    "    # Control false alarm rates by tuning I and N. eg. increase I or N to reduce false alarms\n",
    "    threshold = np.zeros(I-1)\n",
    "    threshold[0:(I-1)] = P[0:(I-1)]\n",
    "    labels = np.zeros(I-1)\n",
    "    for k in np.arange(I,len(P)+1):\n",
    "        mu = np.mean(P[(k-I):k])\n",
    "        sigma = np.std(P[(k-I):k])\n",
    "        T = mu - N*sigma\n",
    "        threshold = np.append(threshold,T)\n",
    "        if (A[k-1] < threshold[k-1]) :\n",
    "            labels = np.append(labels,1)\n",
    "        else:\n",
    "            labels = np.append(labels,0)\n",
    "    return labels, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "np.random.seed(7)\n",
    "########################################################################################\n",
    "# Regression\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "scoring_param = make_scorer(mean_squared_error,greater_is_better=False)\n",
    "\n",
    "rfecv = RFECV(estimator=XGBRegressor(n_jobs=-1), step=1, cv=kf, scoring=scoring_param, n_jobs=-1)\n",
    "FS_model = rfecv.fit(X_train, y_train)\n",
    "\n",
    "ranks = FS_model.ranking_\n",
    "FN =[]\n",
    "for i in range(len(ranks)):\n",
    "    if ranks[i] == 1:\n",
    "        FN.append(Feature_Names[i])\n",
    "print(FN)\n",
    "\n",
    "X = Chiller_Data[FN].as_matrix()\n",
    "X_train, X_test = train_test_split(X, test_size=0.55, shuffle=False)\n",
    "\n",
    "MD = [int(i) for i in np.linspace(1,20,num=5)]\n",
    "LR = np.linspace(0.001,0.1,num=5)\n",
    "NE = [int(i) for i in np.linspace(100,1000,num=10)]\n",
    "########################################################################################\n",
    "p_grid = dict()\n",
    "p_grid = dict(max_depth =  MD, \n",
    "              learning_rate = LR, \n",
    "              n_estimators = NE)\n",
    "\n",
    "model = GridSearchCV(estimator = XGBRegressor(n_jobs=-1), param_grid = p_grid, scoring = scoring_param, \n",
    "                     cv = kf, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "    \n",
    "params = model.best_params_\n",
    "print(\"Best depth: %s Best LR: %f Best Est: %s\" % (params['max_depth'],params['learning_rate'],\n",
    "                                                   params['n_estimators']))\n",
    "    \n",
    "Y_Test_Predicted = model.predict(X_test)\n",
    "    \n",
    "rmse = np.sqrt(mean_squared_error(y_test,Y_Test_Predicted))\n",
    "data_range = y_test.max() - y_test.min()\n",
    "NRMSE = (rmse/data_range) * 100.0\n",
    "RSQ = r2_score(y_test,Y_Test_Predicted)\n",
    "print(\"Normalized RMSE: %0.3f\" % NRMSE)\n",
    "print(\"R-squared: %0.3f\" % RSQ)\n",
    "\n",
    "Labels, Threshold = calc_dyn_threshold(y_test, Y_Test_Predicted, 2, 2)\n",
    "Temp = pd.DataFrame(data={'Actual': y_test, 'Predicted':Y_Test_Predicted, 'Labels':TL_Test, \n",
    "                               'Threshold':Threshold, 'Pred_Labels': Labels})\n",
    "\n",
    "print(\"########################################################################################\")\n",
    "print(\"Confusion Matrix - testing:\")\n",
    "print(confusion_matrix(Temp['Labels'], Temp['Pred_Labels']))\n",
    "tn, fp, fn, tp = confusion_matrix(Temp['Labels'], Temp['Pred_Labels']).ravel()\n",
    "print(\"True Negative, False Positive, False Negative, True Positive {}.\".format([tn, fp, fn, tp]))\n",
    "print(\"False positive means false alarms\")\n",
    "print(\"False Negative means missed faults\")\n",
    "print(\"########################################################################################\")\n",
    "print(\"Classification Report - testing:\")\n",
    "print(classification_report(Temp['Labels'], Temp['Pred_Labels'], target_names=['Normal', 'Fault']))\n",
    "print(\"########################################################################################\")\n",
    "print(\"Accuracy - testing: %0.3f\" % accuracy_score(Temp['Labels'], Temp['Pred_Labels']))\n",
    "print(\"########################################################################################\")\n",
    "print(\"ROC AUC score - testing: %0.3f\" % roc_auc_score(Temp['Labels'], Temp['Pred_Labels']))\n",
    "print(\"########################################################################################\")\n",
    "########################################################################################\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "Data_0 = Temp.loc[Temp['Labels'][Temp['Labels']==0].index]\n",
    "Data_1 = Temp.loc[Temp['Labels'][Temp['Labels']==1].index]\n",
    "ax.scatter(list(Data_0.index), Data_0['Actual'], c=plt.cm.coolwarm(0.), s=200,\n",
    "           edgecolors='y', marker='o', label=u'Actual normal data')\n",
    "ax.scatter(list(Data_1.index), Data_1['Actual'], c=plt.cm.coolwarm(1.), s=200, \n",
    "           edgecolors='y', marker='^', label=u'Actual fault data')\n",
    "plt.plot(list(Temp.index), Temp['Predicted'], 'c-*', lw = 4, ms = 5, label=u'XGBoost Prediction')\n",
    "plt.xlabel('Data index',fontsize=30)\n",
    "plt.ylabel('Heat exchanger efficiency of the sub-cooling section',fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.legend(loc='best',fontsize=30)\n",
    "plt.savefig('M1-Cond-Foul-Actual-Labels-Predictions')\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "Data_0 = Temp.loc[Temp['Pred_Labels'][Temp['Pred_Labels']==0].index]\n",
    "Data_1 = Temp.loc[Temp['Pred_Labels'][Temp['Pred_Labels']==1].index]\n",
    "ax.scatter(list(Data_0.index), Data_0['Actual'], c=plt.cm.coolwarm(0.), s=200, \n",
    "           edgecolors='y', marker='o', label=u'Predicted normal data')\n",
    "ax.scatter(list(Data_1.index), Data_1['Actual'], c=plt.cm.coolwarm(1.), s=200,\n",
    "           edgecolors='y', marker='^', label=u'Predicted fault data')\n",
    "plt.plot(list(Temp.index), Temp['Predicted'], 'c-*', lw = 4, ms = 5, label=u'XGBoost Prediction')\n",
    "plt.plot(list(Temp.index), Temp['Threshold'], 'k--', lw = 4, label=u'Dynamic threshold')\n",
    "plt.xlabel('Data index',fontsize=30)\n",
    "plt.ylabel('Heat exchanger efficiency of the sub-cooling section',fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.legend(loc='best',fontsize=30)\n",
    "plt.savefig('M1-Cond-Foul-XGB-Dynamic-Threshold-Predicted-Labels')\n",
    "\n",
    "importance = model.best_estimator_.get_booster().get_score(importance_type='weight')\n",
    "tuples = [(k, importance[k]) for k in importance]\n",
    "tuples = sorted(tuples, key=lambda s: int(s[0][1:]))\n",
    "features, feature_importance = zip(*tuples)\n",
    "print(features,feature_importance)\n",
    "\n",
    "t1 = time()\n",
    "print('Time taken for this trial %f' %(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Labels, Threshold = calc_dyn_threshold(y_test, Y_Test_Predicted, 30, 2)\n",
    "Temp = pd.DataFrame(data={'Actual': y_test, 'Predicted':Y_Test_Predicted, 'Labels':TL_Test, \n",
    "                               'Threshold':Threshold, 'Pred_Labels': Labels})\n",
    "\n",
    "print(\"########################################################################################\")\n",
    "print(\"Confusion Matrix - testing:\")\n",
    "print(confusion_matrix(Temp['Labels'], Temp['Pred_Labels']))\n",
    "tn, fp, fn, tp = confusion_matrix(Temp['Labels'], Temp['Pred_Labels']).ravel()\n",
    "print(\"True Negative, False Positive, False Negative, True Positive {}.\".format([tn, fp, fn, tp]))\n",
    "print(\"False positive means false alarms\")\n",
    "print(\"False Negative means missed faults\")\n",
    "print(\"########################################################################################\")\n",
    "print(\"Classification Report - testing:\")\n",
    "print(classification_report(Temp['Labels'], Temp['Pred_Labels'], target_names=['Normal', 'Fault']))\n",
    "print(\"########################################################################################\")\n",
    "print(\"Accuracy - testing: %0.3f\" % accuracy_score(Temp['Labels'], Temp['Pred_Labels']))\n",
    "print(\"########################################################################################\")\n",
    "print(\"ROC AUC score - testing: %0.3f\" % roc_auc_score(Temp['Labels'], Temp['Pred_Labels']))\n",
    "print(\"########################################################################################\")\n",
    "########################################################################################\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "Data_0 = Temp.loc[Temp['Labels'][Temp['Labels']==0].index]\n",
    "Data_1 = Temp.loc[Temp['Labels'][Temp['Labels']==1].index]\n",
    "ax.scatter(list(Data_0.index), Data_0['Actual'], c=plt.cm.coolwarm(0.), s=200,\n",
    "           edgecolors='y', marker='o', label=u'Actual normal data')\n",
    "ax.scatter(list(Data_1.index), Data_1['Actual'], c=plt.cm.coolwarm(1.), s=200, \n",
    "           edgecolors='y', marker='^', label=u'Actual fault data')\n",
    "plt.plot(list(Temp.index), Temp['Predicted'], 'c-*', lw = 4, ms = 5, label=u'XGBoost Prediction')\n",
    "plt.xlabel('Data index',fontsize=30)\n",
    "plt.ylabel('Heat exchanger efficiency of the sub-cooling section',fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.legend(loc='best',fontsize=30)\n",
    "#plt.savefig('M1-Cond-Foul-Actual-Labels-Predictions')\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "Data_0 = Temp.loc[Temp['Pred_Labels'][Temp['Pred_Labels']==0].index]\n",
    "Data_1 = Temp.loc[Temp['Pred_Labels'][Temp['Pred_Labels']==1].index]\n",
    "ax.scatter(list(Data_0.index), Data_0['Actual'], c=plt.cm.coolwarm(0.), s=200, \n",
    "           edgecolors='y', marker='o', label=u'Predicted normal data')\n",
    "ax.scatter(list(Data_1.index), Data_1['Actual'], c=plt.cm.coolwarm(1.), s=200,\n",
    "           edgecolors='y', marker='^', label=u'Predicted fault data')\n",
    "plt.plot(list(Temp.index), Temp['Predicted'], 'c-*', lw = 4, ms = 5, label=u'XGBoost Prediction')\n",
    "plt.plot(list(Temp.index), Temp['Threshold'], 'k--', lw = 4, label=u'Dynamic threshold')\n",
    "plt.xlabel('Data index',fontsize=30)\n",
    "plt.ylabel('Heat exchanger efficiency of the sub-cooling section',fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.legend(loc='best',fontsize=30)\n",
    "#plt.savefig('M1-Cond-Foul-XGB-Dynamic-Threshold-Predicted-Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
